import time
import torch
import numpy as np
import logging
import sys
import os
import argparse
import json
import cv2
from pathlib import Path

# è·¯å¾„ä¿®æ­£
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.dirname(current_dir))
sys.path.append("./src")

# [æ›´æ–°] å¯¼å…¥å¿…è¦çš„ Config ç±»
from lerobot.robots.mkrobot.mk_robot import MKRobot, MKRobotConfig
from lerobot.teleoperators.gamepad.gamepad_ik_teleop import GamepadIKTeleop, GamepadIKTeleopConfig
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.teleoperators.utils import TeleopEvents
from lerobot.cameras.opencv import OpenCVCamera, OpenCVCameraConfig # æ˜¾å¼å¯¼å…¥ç›¸æœºé…ç½®

logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",  # å¦‚æœæƒ³è¦æ›´è¯¦ç»†çš„ä¿¡æ¯å¯ä»¥æ”¹ä¸º "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)
logger = logging.getLogger("Pi05-Recorder")

# æŒ‰é”®å®šä¹‰ (Xbox)
# BTN_A = 0  # Start Recording
BTN_Y = 3  # Success & Finish (Hold to mark success, Release to save & home)
# BTN_X = 2  # Fail & Reset (Hold to home)


# ä¸ºäº†å½’ä¸€åŒ–ï¼Œæ ¹æ®mk_robot.pyä¸­çš„é™ä½å€¼ç®—çš„
"""
æˆ‘ä»¬å¯ä»¥å®šä¹‰å¦‚ä¸‹çš„ Scale_Factorï¼ˆå–ç‰©ç†é™ä½åŒºé—´çš„æœ€å¤§ç»å¯¹å€¼ï¼‰ï¼š
J1: $max(|-3.0|, |3.0|) = 3.0$
J2: $max(|0.0|, |3.0|) = 3.0$
J3: $max(|0.0|, |3.0|) = 3.0$
J4: $max(|-1.7|, |1.2|) = 1.7$
J5: $max(|-0.4|, |0.4|) = 0.4$
J6: $max(|-2.0|, |2.0|) = 2.0$
Gripper: $1.0$ (å‡è®¾å¤¹çˆªå·²ç»æ˜¯ $0-1$ èŒƒå›´)
"""
# è¿™é‡Œçš„æ•°å€¼å–è‡ªä½ æä¾›çš„å®‰å…¨é…ç½®ä¸­æ¯ä¸ªå…³èŠ‚çš„æœ€å¤§ç»å¯¹å€¼
JOINT_NORM_SCALE = np.array([3.0, 3.0, 3.0, 1.7, 0.4, 2.0, 1.0])

def process_to_square(img, target_size=448):
    """ å°†å›¾åƒè£å‰ªå¹¶ç¼©æ”¾ä¸ºæ­£æ–¹å½¢ã€‚å…¼å®¹ [C, H, W] å¼ é‡æˆ– Numpy æ•°ç»„ """
    if isinstance(img, torch.Tensor):
        # è½¬æ¢ [C, H, W] -> [H, W, C] ä¾› OpenCV å¤„ç†
        img_np = img.permute(1, 2, 0).cpu().numpy()
    else:
        img_np = img

    h, w = img_np.shape[:2]
    min_dim = min(h, w)
    start_h = (h - min_dim) // 2
    start_w = (w - min_dim) // 2
    img_cropped = img_np[start_h:start_h + min_dim, start_w:start_w + min_dim]
    
    img_resized = cv2.resize(img_cropped, (target_size, target_size), interpolation=cv2.INTER_AREA)
    
    # è½¬æ¢ä¸º uint8 å¹¶è½¬å› [C, H, W] å¼ é‡
    if img_resized.max() <= 1.0:
        img_resized = (img_resized * 255).astype(np.uint8)
    return torch.from_numpy(img_resized.astype(np.uint8)).permute(2, 0, 1)
    

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="env_config_gamepad_record_data.json")
    args = parser.parse_args()

    with open(args.config, 'r') as f: cfg = json.load(f)
    repo_id = cfg['dataset']['repo_id']
    root_dir = Path(cfg['dataset']['root'])
    fps = cfg['env']['fps']
    task_label = cfg['dataset']['task']
    
    features = {
        "observation.state": {"dtype": "float32", "shape": (7,), "names": ["j1","j2","j3","j4","j5","j6","gripper"]},
        "action": {"dtype": "float32", "shape": (7,), "names": ["j1","j2","j3","j4","j5","j6","gripper"]},
        "observation.images.top": {"dtype": "video", "shape": [3, 448, 448], "names": ["c", "h", "w"]},
        "observation.images.wrist": {"dtype": "video", "shape": [3, 448, 448], "names": ["c", "h", "w"]},
    }

    print(f"ğŸš€ å‡†å¤‡é‡‡é›†æ•°æ®: {repo_id}")

    # --- 1. æ•°æ®é›†åˆå§‹åŒ– ---
    if (root_dir / "meta/info.json").exists():
        print(f"ğŸ”„ æ£€æµ‹åˆ°ç°æœ‰æ•°æ®é›†ï¼Œæ­£åœ¨åŠ è½½...")
        dataset = LeRobotDataset(repo_id=repo_id, root=root_dir)
        print(f"âœ… åŠ è½½æˆåŠŸï¼æ¥ç»­ä» Episode {dataset.num_episodes} å¼€å§‹ã€‚")
    else:
        print(f"ğŸ†• æœªæ£€æµ‹åˆ°æ•°æ®é›†ï¼Œæ­£åœ¨åˆ›å»ºæ–°æ•°æ®é›†...")
        dataset = LeRobotDataset.create(
            repo_id=repo_id,
            root=root_dir,
            fps=fps,
            robot_type=cfg['env']['robot']['type'],
            features=features
        )
    episode_idx = dataset.num_episodes

    # --- 2. åˆå§‹åŒ– Robot (å‚è€ƒ run_real_teleop.py) ---
    robot_json_cfg = cfg['env']['robot']
    
    # [æ›´æ–°] ä½¿ç”¨ Config å¯¹è±¡åˆå§‹åŒ–
    mk_robot_config = MKRobotConfig(
        port=robot_json_cfg['port'],
        joint_velocity_scaling=1.0  # é»˜è®¤è®¾ç½®ä¸º 1.0ï¼Œå¦‚éœ€é™åˆ¶é€Ÿåº¦å¯è°ƒä½
    )
    robot = MKRobot(mk_robot_config)

    # åˆå§‹åŒ–ç›¸æœº (ä¿æŒåŸæœ‰é€»è¾‘ï¼Œå› ä¸º run_real_teleop.py é€šå¸¸ä¸å¸¦ç›¸æœº)
    for name, cam_cfg in robot_json_cfg['cameras'].items():
        cam_config = OpenCVCameraConfig(
            index_or_path=cam_cfg['index_or_path'], 
            fps=cam_cfg['fps'], 
            width=cam_cfg['width'], 
            height=cam_cfg['height']
        )
        robot.cameras[name] = OpenCVCamera(cam_config)
    
    robot.connect()
    print(f"âœ… çœŸæœºä¸ç›¸æœºè¿æ¥æˆåŠŸ")

    # --- 3. åˆå§‹åŒ– Teleop (æ ¸å¿ƒä¿®æ”¹) ---
    teleop_json_cfg = cfg['env']['teleop']

    # [æ›´æ–°] å…ˆåˆ›å»º Config å¯¹è±¡ï¼Œæ˜¾å¼åŒ…å«é€Ÿåº¦å‚æ•°
    teleop_config = GamepadIKTeleopConfig(
        type="gamepad_ik",
        urdf_path=teleop_json_cfg['urdf_path'],
        mesh_dir=teleop_json_cfg['mesh_dir'],
        fps=fps,
        visualize=teleop_json_cfg.get('visualize', True),
        inverse_kinematics=teleop_json_cfg.get('inverse_kinematics', {}),
        # å¯ä»¥åœ¨è¿™é‡Œè°ƒæ•´é€Ÿåº¦ï¼Œè¦†ç›–é»˜è®¤å€¼
        trans_speed=teleop_json_cfg.get('trans_speed', 0.002), 
        rot_speed=teleop_json_cfg.get('rot_speed', 0.02)
    )

    # [æ›´æ–°] ä¼ å…¥ config å‚æ•°ï¼Œè§£å†³ 'AttributeError: NoneType has no attribute id'
    teleop = GamepadIKTeleop(
        config=teleop_config,  # <--- å…³é”®ä¿®æ”¹ï¼šä¼ å…¥ config å¯¹è±¡
        urdf_path=teleop_config.urdf_path,
        mesh_dir=teleop_config.mesh_dir,
        fps=teleop_config.fps,
        visualize=teleop_config.visualize,
        inverse_kinematics=teleop_config.inverse_kinematics
    )
    teleop.connect()
    print("âœ… æ‰‹æŸ„ä¸ IK æ ¸å¿ƒå°±ç»ª")

    print("\n" + "="*50)
    print("ğŸ® æ“ä½œè¯´æ˜:")
    print("   [RB æŒ‰ä½] : æ¿€æ´»æ§åˆ¶ (IK)")
    print("   [A é”®]    : â–¶ï¸ å¼€å§‹å½•åˆ¶ (Start)")
    print("   [Y é”®]    : âœ… ä¿å­˜å¹¶å½’ä½")
    print("   [B é”®]    : âœ… ç»“æŸé€€å‡º")
    print("   [x é”®]    : â™»ï¸ é•¿æŒ‰å½’ä½ (è§†ä¸ºå¤±è´¥å¹¶ä¿å­˜/ä¸¢å¼ƒ)")
    print("="*50 + "\n")
  
    episode_data = None

    
    MAX_TIME_S = cfg['processor']['reset']['control_time_s']
    episode_start_time = 0

    try:
        while episode_idx < cfg['dataset']['num_episodes_to_record']:
            # --- é˜¶æ®µ 1: ç­‰å¾…æŒ‰ä¸‹ A é”®å¼€å§‹å½•åˆ¶ ---
            logger.info(f"âŒ› ç­‰å¾…å¼€å§‹å½•åˆ¶ Episode {episode_idx} (æŒ‰ A é”®)...")
            while True:
                obs = robot.get_observation()
                # å…¼å®¹ Teleop è¿”å›å­—å…¸çš„æƒ…å†µ
                action_out = teleop.get_action(obs)
                action_tensor = action_out["action"] if isinstance(action_out, dict) else action_out
                robot.send_action(action_tensor)
                
                events = teleop.get_teleop_events()
                if events.get(TeleopEvents.START_RECORDING): # A é”®
                    break
                if events.get(TeleopEvents.TERMINATE_EPISODE): # B é”®
                    return # ç›´æ¥é€€å‡º main
                time.sleep(1.0 / fps)

            # --- é˜¶æ®µ 2: å½•åˆ¶ä¸­ ---
            logger.info(f"ğŸ”´ å½•åˆ¶ä¸­ Episode {episode_idx} (æŒ‰ Y é”®ä¿å­˜)...")
            episode_data = {k: [] for k in ["observation.images.top", "observation.images.wrist", "observation.state", "action"]}
            
            while True:
                loop_start = time.time()
                obs = robot.get_observation()
                action_out = teleop.get_action(obs)
                action_tensor = action_out["action"] if isinstance(action_out, dict) else action_out
                robot.send_action(action_tensor)
                
                # ã€ä¿®å¤ KeyErrorã€‘ä½¿ç”¨ obs.keys() æä¾›çš„å®Œæ•´è·¯å¾„
                episode_data["observation.state"].append(obs["observation.state"].cpu().numpy())
                episode_data["action"].append(action_tensor.cpu().numpy())
                episode_data["observation.images.top"].append(obs["observation.images.top"])
                episode_data["observation.images.wrist"].append(obs["observation.images.wrist"])
                
                events = teleop.get_teleop_events()
                
                # --- é˜¶æ®µ 3: ä¿å­˜é€»è¾‘ (Y é”®) ---
                if events.get(TeleopEvents.SUCCESS):
                    logger.info(f"ğŸ’¾ æ­£åœ¨å¤„ç†å¹¶ä¿å­˜ Episode {episode_idx}...")
                    num_frames = len(episode_data["action"])
                    for i in range(num_frames):
                        norm_state = episode_data["observation.state"][i] / JOINT_NORM_SCALE
                        norm_action = episode_data["action"][i] / JOINT_NORM_SCALE
                        norm_state = np.clip(norm_state, -1.0, 1.0)
                        norm_action = np.clip(norm_action, -1.0, 1.0)
                        frame = {
                            "observation.state": norm_state.astype(np.float32),
                            "action": norm_action.astype(np.float32),
                            "observation.images.top": process_to_square(episode_data["observation.images.top"][i]),
                            "observation.images.wrist": process_to_square(episode_data["observation.images.wrist"][i]),
                            "task": cfg['dataset']['task']
                        }
                        dataset.add_frame(frame)
                    
                    dataset.save_episode()
                    logger.info(f"âœ… Episode {episode_idx} å·²ä¿å­˜ï¼")
                    episode_idx = dataset.num_episodes
                    
                    # ä¸²å£æ’ç©º & è‡ªåŠ¨å½’ä½ (æ‚¨è¦æ±‚çš„ç¨³å®šå½’é›¶é€»è¾‘)
                    print("ğŸ§¹ æ¸…ç†ä¸²å£...", end="")
                    flush_start = time.time()
                    while time.time() - flush_start < 1.0:
                        try:
                            _ = robot.get_observation()
                            _ = teleop.get_action(_)
                        except: pass
                        time.sleep(1.0/fps)
                    print("å®Œæˆ")
                    
                    if not teleop.core.is_homing:
                        teleop.core.start_homing()
                    break # è·³å‡ºå½•åˆ¶å¾ªç¯ï¼Œå›åˆ°ç­‰å¾… A é”®é˜¶æ®µ

                if events.get(TeleopEvents.TERMINATE_EPISODE): # B é”®
                    return

                # é¢‘ç‡æ§åˆ¶
                dt = time.time() - loop_start
                time.sleep(max(0, (1.0/fps) - dt))

    finally:
        dataset.finalize()
        robot.disconnect()
        teleop.disconnect()    



if __name__ == "__main__":
    main()